{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - Stellenanzeigen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and import of German Stopwords, execution only needed once\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from langdetect import detect, DetectorFactory\n",
    "from ast import literal_eval\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading synonyms into a dataframe\n",
    "kode = pd.read_excel(\"kode_data.xlsx\", header=1)\n",
    "\n",
    "# Keep one of the df commented:\n",
    "columns = [ 'title', \n",
    "            'location', \n",
    "            'company',\n",
    "            'job_dt',\n",
    "            'year_month',\n",
    "            'contract_type',\n",
    "            'work_type',\n",
    "            'pers_resp',\n",
    "            'language',\n",
    "            'introduction_clean_tokens', \n",
    "            'description_clean_tokens',\n",
    "            'profile_clean_tokens', \n",
    "            'weoffer_clean_tokens']\n",
    "\n",
    "\n",
    "# Reading full dataset into dataframe\n",
    "df = pd.read_csv('jobs_tokenized.csv', encoding='UTF-8', usecols=columns)\n",
    "\n",
    "# Reading sample dataset into dataframe\n",
    "# df = pd.read_excel(\"jobs_sample.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "350018ee1cc1cfe64da6ac863102ac5ad3a4595f3b62df7ec04d5549dd0ea414"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dhbw': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
